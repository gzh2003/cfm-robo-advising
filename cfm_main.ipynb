{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Math, Latex\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy_financial as npf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Assignment\n",
    "### Team Number: 09\n",
    "### Team Member Names: Germain, Padtmesh, Jin\n",
    "### Team Strategy Chosen: Safe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy\n",
    "\n",
    "Our strategy is largely composed of two components\n",
    "1. Algorithmically selecting 25 stocks\n",
    "2. Generating portfolios composed of the above 25 stocks with different weightings and selecting a specific portfolio based on it's volatility (e.g. the minimum volatility portfolio) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Algorithmically selecting 25 stocks\n",
    "Our initial considerations for part 1) included:\n",
    "\n",
    "  1. Standard Deviation\n",
    "     - Interconnectedness of the portfolio is largely unknown and when a portfolio is compromised of multiple different stocks, the interconnectedness of the risk is embedded in its intensity\n",
    "  2. Correlation\n",
    "     - Selecting based on correlation would involve a lot of intermediate recalculation\n",
    "     - Individual stocks may have variable volatility\n",
    "  1. Industry Specific Adjustments\n",
    "     - This would involve running a randomized algorithm against a set of datasets to generate coefficients for industry specific adjustments\n",
    "     - Defensive industries comprise of businesses that are relatively stable and immune to economic fluctuations\n",
    "     - Must be done in combination with another factor\n",
    "\n",
    "We opted to use only standard deviation as the length of the competition is relatively short, and since the other options (specifically industry specific adjustments) aren't suited for the condensed timeframe. We also decided on picking the maximum number of stocks per the constraints of the project, as this would help us diversify the risk across the portfolio since we have opted for a safe portfolio. The standard deviation shows the average fluctuation in the price of stocks, so the lower the standard deviation, the less volatile the price, and thus the safer the portfolio.\n",
    "\n",
    "In this part, we read in the tickers, filter and sort them based on their standard deviation. Then we select the first 25 stocks with the lowest standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterByDenom(ticker):\n",
    "    # Check if a stock is a \"US listed stock\"\n",
    "    return ticker.info['currency'] != 'USD'\n",
    "\n",
    "def filterByVol(hist):\n",
    "    # Check the average monthly volume\n",
    "    return  hist['Volume'].mean() < 200000\n",
    "\n",
    "def filterByTDays(df_hist):\n",
    "    df = df_hist.copy()\n",
    "    # Iterate across time range with months January to October\n",
    "    for month in range(1, 11):\n",
    "        # Get numerical month value of each index\n",
    "        idx = pd.to_datetime(df.index).month\n",
    "        # Get subset of df_hist of a specific month\n",
    "        df_month = df.loc[idx == month]\n",
    "        # Filter by number of entries/trading days for a specific month \n",
    "        if (len(df_month) < 20):\n",
    "            df.drop(df[idx == month].index, inplace=True)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHist(tickers):\n",
    "    # Set defaults for timeframe\n",
    "    start_date = '2022-01-01'\n",
    "    end_date = '2022-11-01' # adjustment for non-inclusive param end\n",
    "\n",
    "    # Create dataframe to hold historic data from tickers\n",
    "    df_sv = pd.DataFrame()\n",
    "\n",
    "    # Get the closing price of each ticker \n",
    "    for tick in tickers['Tickers']:\n",
    "        # Call API for ticker data\n",
    "        temp = yf.Ticker(tick)\n",
    "\n",
    "        # Get historical data\n",
    "        #   Note: the method history() prints out the delisted message\n",
    "        temp_hist = temp.history(start=start_date, end=end_date, interval='1d')\n",
    "\n",
    "        # Filter by denom and volume of non-delisted tickers\n",
    "        if (not temp_hist.empty) and (not (filterByDenom(temp) or filterByVol(temp_hist))):\n",
    "            # Get Closing Price as a DataFrame\n",
    "            df_sv[tick] = pd.DataFrame(temp_hist['Close'])\n",
    "\n",
    "    # Remove indeterminate or faulty values\n",
    "    df_sv.dropna(axis=1,how='all',inplace = True)\n",
    "    df_sv.dropna(inplace = True)\n",
    "\n",
    "    # Filter by number of trading days\n",
    "    df_sv = filterByTDays(df_sv)\n",
    "    return df_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorHistPct(df_pct):\n",
    "    # Sort arrays by std\n",
    "    return df_pct.reindex(df_pct.std().sort_values().index, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReturns(pct, weights):\n",
    "    # Calculate annuzalized returns\n",
    "    return (np.sum(pct.mean() * weights)) * 253\n",
    "\n",
    "def getStd(pct, weights):\n",
    "    # Calculate annuzalized std\n",
    "    return np.sqrt(np.transpose(weights) @ (pct.cov() * 253) @ weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2)  Portfolio Generation\n",
    "From the 25 stocks we've selected above, we now calulate weightings for those stocks such that we minimize the volatility of the portfolio through the allocation of the portfolio weights.\n",
    "\n",
    "This is fundamentally an optimization problem, however even with the reduced range of weights of 2-25% instead of 0-100%,\n",
    "as a computer can only make 10^8 computations per second, it would take far too long to generate the weights with a traditional algorithm.\n",
    "\n",
    "As a result we opted to use a randomized algorithm. \n",
    "\n",
    "The algorithm functions as follows:\n",
    "1. we generate values using a uniform random number generation method\n",
    "   - the reason we use an uniform generation method is to keep our portfolios from being skewed towards a specific weighting       \n",
    "2. set those numbers as weights to our portfolio(adjusting for the constraints of the assignment)\n",
    "\n",
    "We repeat the above steps for 10^4 different portfolios\n",
    "\n",
    "Note: 10^5 is our preferred value as it provides a fairly good approximation for our needs, however, the run-time is around 4 minutes, so we've decided to use 10^4 instead\n",
    "\n",
    "\n",
    "Generating portfolios of 10^n where n>5 doesn't provide much benefits relative to the amount of time it takes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randSimulation(pct):\n",
    "    # Number of random portolfios to generate\n",
    "    # Possible consideration is n = 10**5 since it provides a more accurate approximation\n",
    "        # Note: generation 10**x portfolios where x>5 produces negligible results\n",
    "        #   and the benefits are largely outweighed by the runtime\n",
    "    n = 10**4 \n",
    "    \n",
    "    # Get the number of tickers\n",
    "    ticker_count = len(pct.columns)\n",
    "\n",
    "    # Lists to store portfolio data\n",
    "    list_return = []\n",
    "    list_std = []\n",
    "    list_weight = []\n",
    "\n",
    "    # Generate n random portfolios\n",
    "    for p in range(n):\n",
    "        # Get random values between 0 and 1\n",
    "        #   Note: we use the uniform generation method as we want the samples to be dispersed evenly \n",
    "        weights = np.random.uniform(size= ticker_count)\n",
    "\n",
    "        # Calculating and establishing lower bound for random portfolio weights\n",
    "        #   Note: in establishing this lower bound we no longer need to consider the upper bound as it \n",
    "        #       would be impossible for any one ticker to have more than 25% allocation with the given lower bound\n",
    "        low = 0.02\n",
    "        temp = weights\n",
    "        temp = (temp/temp.sum()*(1-low*ticker_count))\n",
    "        weights = temp+low\n",
    "\n",
    "        # Store randomly generated portfolio data in lists\n",
    "        list_weight.append(weights)\n",
    "        list_return.append(getReturns(pct,weights))\n",
    "        list_std.append(getStd(pct,weights))\n",
    "\n",
    "    # Convert list to np arrays\n",
    "    arr_return = np.array(list_return)\n",
    "    arr_std = np.array(list_std)\n",
    "    arr_weight = np.array(list_weight)\n",
    "\n",
    "    return arr_return, arr_std, arr_weight\n",
    "\n",
    "\n",
    "\n",
    "def graphSimulation(returns, stds, weights):\n",
    "    # Get information for max sharpe ratio portfolio\n",
    "    maxs_index = np.argmax(returns/stds)\n",
    "    maxs_std = stds[maxs_index] \n",
    "    maxs_return = returns[maxs_index] \n",
    "    ms_weight = weights[maxs_index]\n",
    "    \n",
    "    # Get information for min volatility portfolio\n",
    "    minv_index = np.argmin(stds)\n",
    "    minv_std = stds[minv_index]\n",
    "    minv_return = returns[minv_index]\n",
    "    minv_weight = weights[minv_index]\n",
    "\n",
    "    print('Min Volatility Portfolio Weights:')\n",
    "    print(minv_weight)\n",
    "\n",
    "    print('Min Volatility:')\n",
    "    print(minv_std)\n",
    "\n",
    "    # Adjust figure size\n",
    "    plt.figure(figsize=(20, 10))\n",
    "\n",
    "    # Plot generated portfolios\n",
    "    plt.scatter(stds,returns, c=(returns/stds), cmap='winter', s=12, alpha=0.4)\n",
    "    plt.colorbar(label='Sharpe Ratio', shrink=0.7, cmap='winter')\n",
    "\n",
    "    # Plot max sharpe ratio portoflio\n",
    "    plt.scatter(maxs_std,maxs_return,c='plum' , s=120,marker='D', label='Maximum Sharpe Ratio Portfolio')\n",
    "    # Plot min volatility portfolio\n",
    "    plt.scatter(minv_std,minv_return,c='palevioletred', s=120, marker='D',label='Minimum Volatility Portfolio')\n",
    "\n",
    "    # Labels and elements \n",
    "    plt.legend()\n",
    "    plt.title(' Volatility-Returns of Generated Portfolios')\n",
    "    plt.xlabel('Annualized Portfolio Volatility')\n",
    "    plt.ylabel('Annualized Portfolio Returns')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in csv file containing tickers\n",
    "tickers = pd.read_csv('Tickers.csv', names = ['Tickers'])\n",
    "display(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Historic Data for each ticker\n",
    "hist = getHist(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct dataframe of percentage change of each stock\n",
    "hist_pct = hist.pct_change()\n",
    "\n",
    "# Sort hist_pct based on std\n",
    "hist_pct = sorHistPct(hist_pct)\n",
    "\n",
    "# Create new dataframe inplace from the first 25 tickers (25 lowest std)\n",
    "hist_pct = hist_pct.iloc[:,:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from randomly generated portfolios\n",
    "gen_return, gen_std, gen_weights = randSimulation(hist_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph randomly generated portfolios\n",
    "graphSimulation(gen_return, gen_std, gen_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk-Return Graph of Generated Portfolios\n",
    "The graph that is presented below follows the calculations we made in order to get the minimum variance portfolio. The blue diamond indicator represents our minimum variance portfolio that we will be using. It is a collection of 25 different stocks that we have combined after sorting the standard deviation of the stocks that we were given (after filtering out the non-US based stocks), as we have opted for the safe portfolio, hence utilizing the lowest standard deviation stocks. After doing that, the random generator code that we created ran 10^4 calculations in order to locate our minimum variance portfolio, hence from there we are then able to get an approximation of our desired weightings in order to get out optimal portfolio wich minimizes volatility and is considered to be safe.\n",
    "\n",
    "We have included the maximum Sharpe ratio since this is a widely used method in order to measure risk-adjusted relative returns. It compares a fund's historical or projected returns relative to an investment benchmark with the historical or expected variability of such returns. We decided to represent the difference between the Sharpe ratio and the minimum variance portfolio to show the difference between them. We decided not to use Sharpe ratio as there could be higher risk associated towards those weightings of stocks as it depends on the returns of the portfolio in order to offset the risk. Therefore the portfolio weightings based off the maximum Sharpe ratio as seen below represented by the red diamond could be associated with higher risk even though there’s a higher return, which is not the optimal weightings to use since we have opted for a safe portfolio.\n",
    "\n",
    "It should also be noted that this method of analyzing various possible portfolios of the given stocks, draws from the Markowitz model, which is foundational to Modern portfolio theory.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores the tickers from hist_oct in a list\n",
    "tickers = hist_pct.columns\n",
    "# Get the position of the miimum standard deviation\n",
    "minv_index = np.argmin(gen_std)\n",
    "# Get the min weights\n",
    "minv_weight = gen_weights[minv_index]\n",
    "\n",
    "# Create Portfolio Final\n",
    "Portfolio_Final = pd.DataFrame()\n",
    "# Portfolio_Final = pd.DataFrame(columns=['Tickers', 'Price', 'Shares', 'Value', 'Weight'])\n",
    "for i in range(25):\n",
    "        # Set time range to get ticker data\n",
    "        Start_Date ='2022-11-25'\n",
    "        End_date = '2022-11-26'# adjustment for non-inclusive end\n",
    "        # Initial investment\n",
    "        Investment = 500000\n",
    "        Stock_a = yf.Ticker(tickers[i])\n",
    "        Stock_a_hist = Stock_a.history(start=Start_Date)\n",
    "        Closing_Price = Stock_a_hist['Close']\n",
    "        Shares = ((minv_weight[i] * Investment) / Closing_Price)\n",
    "        Value = Shares * Closing_Price\n",
    "        Portfolio_Final_2 = pd.DataFrame({'Tickers': tickers[i], 'Price': Closing_Price, 'Shares': Shares,\n",
    "                                       'Value': Value, 'Weight': minv_weight[i]})\n",
    "        Portfolio_Final = pd.concat([Portfolio_Final, Portfolio_Final_2], ignore_index=True)\n",
    "\n",
    "# Reindex portfolio from 1\n",
    "Portfolio_Final.index = np.arange(1, len(Portfolio_Final) + 1)\n",
    "display(Portfolio_Final)\n",
    "print('Total:')\n",
    "print('$'+ str(Portfolio_Final['Value'].sum())+' USD')\n",
    "print('Total weight:')\n",
    "print(str(Portfolio_Final['Weight'].sum()) + '%') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Stocks_Final\n",
    "Stocks_Final = pd.DataFrame({'Tickers': Portfolio_Final['Tickers'],'Shares': Portfolio_Final['Shares']})\n",
    "Stocks_Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create csv file from Stock_Final\n",
    "Stocks_Final.to_csv(\"Stocks_Group_09.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution Declaration\n",
    "\n",
    "The following team members made a meaningful contribution to this assignment:\n",
    "\n",
    "Germain, Padtmesh, Jin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
